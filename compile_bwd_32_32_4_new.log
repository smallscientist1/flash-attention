

torch.__version__  = 1.12.1


running install
running bdist_egg
running egg_info
writing flash_attn.egg-info/PKG-INFO
writing dependency_links to flash_attn.egg-info/dependency_links.txt
writing requirements to flash_attn.egg-info/requires.txt
writing top-level names to flash_attn.egg-info/top_level.txt
reading manifest file 'flash_attn.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
adding license file 'LICENSE'
adding license file 'AUTHORS'
writing manifest file 'flash_attn.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
running build_ext
building 'flash_attn_2_cuda' extension
Emitting ninja build file /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/12] /usr/local/cuda-11.4/bin/nvcc  -I/home/v-feiychen/flash-attention/csrc/flash_attn -I/home/v-feiychen/flash-attention/csrc/flash_attn/src -I/home/v-feiychen/flash-attention/csrc/cutlass/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/TH -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.4/include -I/anaconda/envs/flashattention/include/python3.9 -c -c /home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu -o /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v -lineinfo -gencode arch=compute_80,code=sm_80 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
FAILED: /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.o 
/usr/local/cuda-11.4/bin/nvcc  -I/home/v-feiychen/flash-attention/csrc/flash_attn -I/home/v-feiychen/flash-attention/csrc/flash_attn/src -I/home/v-feiychen/flash-attention/csrc/cutlass/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/TH -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.4/include -I/anaconda/envs/flashattention/include/python3.9 -c -c /home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu -o /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v -lineinfo -gencode arch=compute_80,code=sm_80 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/softmax.h(217): error: static assertion failed
          detected during:
            instantiation of "void flash::apply_dropout(cute::Tensor<Engine, Layout> &, uint8_t, unsigned long long, unsigned long long, uint32_t, uint32_t, uint32_t) [with encode_dropout_in_sign_bit=true, Engine=cute::ViewEngine<std::remove_cv_t<std::remove_reference_t<float &>> *>, Layout=cute::Layout<cute::Shape<cute::Shape<cute::_2, cute::_2, cute::_2>, cute::_1, cute::_1>, cute::Stride<cute::tuple<cute::_1, cute::_2, cute::constant<int, 4>>, cute::constant<int, 0>, cute::constant<int, 0>>>]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(859): here
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::bfloat16_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::bfloat16_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::bfloat16_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu(9): here

33 errors detected in the compilation of "/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_bf16_sm80.cu".
[2/12] /usr/local/cuda-11.4/bin/nvcc  -I/home/v-feiychen/flash-attention/csrc/flash_attn -I/home/v-feiychen/flash-attention/csrc/flash_attn/src -I/home/v-feiychen/flash-attention/csrc/cutlass/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/TH -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.4/include -I/anaconda/envs/flashattention/include/python3.9 -c -c /home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu -o /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v -lineinfo -gencode arch=compute_80,code=sm_80 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
FAILED: /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.o 
/usr/local/cuda-11.4/bin/nvcc  -I/home/v-feiychen/flash-attention/csrc/flash_attn -I/home/v-feiychen/flash-attention/csrc/flash_attn/src -I/home/v-feiychen/flash-attention/csrc/cutlass/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/TH -I/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/THC -I/usr/local/cuda-11.4/include -I/anaconda/envs/flashattention/include/python3.9 -c -c /home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu -o /home/v-feiychen/flash-attention/build/temp.linux-x86_64-cpython-39/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=-v -lineinfo -gencode arch=compute_80,code=sm_80 --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=flash_attn_2_cuda -D_GLIBCXX_USE_CXX11_ABI=0
/anaconda/envs/flashattention/lib/python3.9/site-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/softmax.h(217): error: static assertion failed
          detected during:
            instantiation of "void flash::apply_dropout(cute::Tensor<Engine, Layout> &, uint8_t, unsigned long long, unsigned long long, uint32_t, uint32_t, uint32_t) [with encode_dropout_in_sign_bit=true, Engine=cute::ViewEngine<std::remove_cv_t<std::remove_reference_t<float &>> *>, Layout=cute::Layout<cute::Shape<cute::Shape<cute::_2, cute::_2, cute::_2>, cute::_1, cute::_1>, cute::Stride<cute::tuple<cute::_1, cute::_2, cute::constant<int, 4>>, cute::constant<int, 0>, cute::constant<int, 0>>>]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(859): here
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, false, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=true, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=true, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=true]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_kernel.h(853): error: static assertion failed
          detected during:
            instantiation of "void flash::compute_dq_dk_dv_1colblock<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Is_first,Is_last,Seq_parallel,Params>(const Params &, int, int, int) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Is_first=false, Is_last=false, Seq_parallel=true, Params=Flash_bwd_params]" 
(1591): here
            instantiation of "void flash::compute_dq_dk_dv_seqk_parallel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K,Params>(const Params &) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false, Params=Flash_bwd_params]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(28): here
            instantiation of "void flash_bwd_dq_dk_dv_loop_seqk_parallel_kernel<Kernel_traits,Is_dropout,Is_causal,Is_even_MN,Is_even_K>(Flash_bwd_params) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false, Is_causal=false, Is_even_MN=false, Is_even_K=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(62): here
            instantiation of "void run_flash_bwd_seqk_parallel<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(134): here
            instantiation of "void run_flash_bwd<Kernel_traits,Is_dropout>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with Kernel_traits=Flash_bwd_kernel_traits<512, 32, 32, 4, 2, 2, 2, false, true, cutlass::half_t, Flash_kernel_traits<512, 32, 32, 4, cutlass::half_t>>, Is_dropout=false]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_launch_template.h(365): here
            instantiation of "void run_mha_bwd_hdim512<T>(Flash_bwd_params &, cudaStream_t, __nv_bool) [with T=cutlass::half_t]" 
/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu(9): here

33 errors detected in the compilation of "/home/v-feiychen/flash-attention/csrc/flash_attn/src/flash_bwd_hdim512_fp16_sm80.cu".
ninja: build stopped: interrupted by user.
Traceback (most recent call last):
  File "/anaconda/envs/flashattention/bin/ninja", line 33, in <module>
    sys.exit(load_entry_point('ninja==1.11.1', 'console_scripts', 'ninja')())
  File "/anaconda/envs/flashattention/lib/python3.9/site-packages/ninja/__init__.py", line 51, in ninja
    raise SystemExit(_program('ninja', sys.argv[1:]))
  File "/anaconda/envs/flashattention/lib/python3.9/site-packages/ninja/__init__.py", line 47, in _program
    return subprocess.call([os.path.join(BIN_DIR, name)] + args, close_fds=False)
  File "/anaconda/envs/flashattention/lib/python3.9/subprocess.py", line 351, in call
    return p.wait(timeout=timeout)
  File "/anaconda/envs/flashattention/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/anaconda/envs/flashattention/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/anaconda/envs/flashattention/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
